# Provider Official API Alignment (Gap Tracker)

This document is a *living* checklist to compare each shipped `llm_dart_*`
provider package against the provider's **official API surface** (excluding
deprecated/legacy features where practical).

Notes:

- â€œOfficial docsâ€ are sometimes blocked by region/anti-bot in this environment.
  When that happens, this tracker records the limitation and relies on:
  - publicly available official OpenAPI specs (when available), and/or
  - live smoke checks (`tool/live_provider_alignment.dart`) using real keys.
- LLM Dart intentionally does **not** maintain a provider/model capability
  matrix. This tracker focuses on **API surface availability** and obvious
  implementation/typing gaps, not per-model behavior.

## Scope

- Included: providers shipped in this repo (`docs/providers/README.md`)
- Excluded: providers not supported in the umbrella package

## Legend

- âœ… Supported (implemented + covered by docs/tests)
- ğŸŸ¡ Partial / best-effort / model-dependent
- â¬œ Not supported (non-deprecated feature exists in official API)
- ğŸš« Out of LLM Dart scope (no standard surface yet)
- ğŸ”’ Official docs not accessible from this environment

## Summary (by provider)

| Provider | Package | Official docs source(s) used | Doc access | Key surfaces in official API | LLM Dart coverage | Notable gaps (non-deprecated) |
|---|---|---|---|---|---|---|
| OpenAI | `llm_dart_openai` | OpenAPI spec: `https://app.stainless.com/api/spec/documented/openai/openapi.documented.yml` | âœ… | chat, responses, embeddings, images, audio, files, moderation, assistants, models | ğŸŸ¡ | Realtime API (WebSocket), Batch, Fine-tuning, Vector stores management (beyond built-in tools) |
| Anthropic | `llm_dart_anthropic` | Live API + existing repo docs | ğŸ”’ | messages, models, token count, files, tool use | ğŸŸ¡ | Batches / additional endpoints (cannot confirm here due to docs access) |
| Google (Gemini) | `llm_dart_google` | `https://ai.google.dev/gemini-api/docs` | ğŸŸ¡ | generateContent/stream, embeddings, file APIs, cached content, countTokens | ğŸŸ¡ | Files API, cached contents, countTokens endpoint parity |
| Groq | `llm_dart_groq` | Live API + OpenAI-compatible baseline | ğŸ”’ | OpenAI-compatible chat completions | ğŸŸ¡ | Additional Groq-specific endpoints (docs blocked) |
| DeepSeek | `llm_dart_deepseek` | `https://api-docs.deepseek.com/` (+ sitemap) | âœ… | chat completions, completions, models, account/billing | ğŸŸ¡ | Account/billing endpoints, completions/FIM guides as first-class APIs |
| xAI | `llm_dart_xai` | Live API + existing repo docs | ğŸ”’ | OpenAI-compatible chat + Responses API + search | ğŸŸ¡ | Official docs blocked (cannot enumerate extra endpoints) |
| OpenRouter | (config via) `llm_dart_openai_compatible` | `https://openrouter.ai/docs` | âœ… | OpenAI-compatible chat + routing/model APIs | ğŸŸ¡ | OpenRouter model listing / credits endpoints (not exposed as first-class) |
| Ollama | `llm_dart_ollama` | `https://github.com/ollama/ollama/blob/main/docs/api.md` | âœ… | chat, generate, embeddings, model management | ğŸŸ¡ | Pull/push/create/copy/delete/ps endpoints (not exposed) |
| MiniMax | `llm_dart_minimax` | `https://platform.minimax.io/docs/api-reference/text-anthropic-api` | ğŸŸ¡ | Anthropic-compatible Messages API | âœ… | MiniMax OpenAI-compatible API surface (out of scope; provider targets Anthropic route) |
| ElevenLabs | `llm_dart_elevenlabs` | OpenAPI spec: `https://api.elevenlabs.io/openapi.json` | âœ… | TTS, STT, speech-to-speech, alignment, voices, history, workspace | ğŸŸ¡ | Speech-to-speech, forced alignment, history/studio/workspace APIs, realtime session transport |

---

## Live smoke checks (this environment)

Ran:

- `dart run tool/live_provider_alignment.dart --providers=openai,anthropic,google,groq,deepseek,xai,xai.responses,openrouter,minimax,elevenlabs`

Results snapshot (no keys printed):

- OpenAI: `request_forbidden` (unsupported country/region/territory)
- Google: `QuotaExceededError` (free-tier quota limit reported as `0`)
- Groq: `Forbidden` (auth/region/account issue)
- MiniMax: `invalid api key` (for China region, set `MINIMAX_BASE_URL=https://api.minimaxi.com/anthropic/v1/`)
- OK: Anthropic, DeepSeek, xAI, xAI (Responses), OpenRouter, ElevenLabs (TTS)

## OpenAI (`llm_dart_openai`)

Official surfaces (from OpenAPI spec):

- âœ… Chat Completions: `POST /v1/chat/completions`
- âœ… Responses: `POST /v1/responses` + lifecycle operations (get/delete/cancel, list items)
- âœ… Embeddings: `POST /v1/embeddings`
- âœ… Images: `POST /v1/images/*`
- âœ… Audio: `POST /v1/audio/speech`, `POST /v1/audio/transcriptions`, `POST /v1/audio/translations`
- âœ… Files: `POST/GET/DELETE /v1/files`, `GET /v1/files/{id}/content`
- âœ… Moderation: `POST /v1/moderations`
- âœ… Assistants: assistants/threads/runs/messages
- âœ… Models: `GET /v1/models`
- ğŸš« Fine-tuning / Batch / Administration APIs (not currently in LLM Dart surface)
- â¬œ Realtime API (WebSocket) (LLM Dart has `LLMCapability.realtimeAudio` but OpenAI provider does not implement it yet)

Notes:

- LLM Dart supports both OpenAI Chat Completions and the OpenAI-only Responses API.
  Responses is opt-in via `providerOptions['openai']['useResponsesAPI']` or when
  OpenAI built-in tools are configured.

## Anthropic (`llm_dart_anthropic`)

Doc access:

- ğŸ”’ `platform.claude.com/docs/*` is unavailable in this environment (region block).

Verified via implementation + live checks:

- âœ… Messages API (chat + streaming)
- âœ… Tool use (function calling)
- âœ… Vision / reasoning (model-dependent)
- âœ… Models listing (Anthropic models endpoint)
- âœ… Token counting endpoint support (provider method)
- ğŸŸ¡ Files API (implemented; should be validated with live checks)

## Google (Gemini) (`llm_dart_google`)

Official docs:

- `https://ai.google.dev/gemini-api/docs`

LLM Dart coverage:

- âœ… `generateContent` / streaming generate content
- âœ… Embeddings
- âœ… Provider-native web search tool injection (grounding)
- ğŸŸ¡ Image generation (model-dependent; enabled via provider options)
- ğŸŸ¡ Audio output / TTS via Gemini audio modality (exposed via provider-agnostic `TextToSpeechCapability`; requires a TTS-capable Gemini model)
- â¬œ Files API (upload/manage referenced files) as a first-class capability
- â¬œ Cached contents / context caching endpoints as a first-class API
- â¬œ Token counting endpoint parity (if/when supported in official API)

## DeepSeek (`llm_dart_deepseek`)

Official docs:

- `https://api-docs.deepseek.com/`

LLM Dart coverage:

- âœ… OpenAI-compatible Chat Completions (+ streaming)
- âœ… Tool calling (OpenAI-compatible)
- âœ… Model listing (`/models`)
- â¬œ Account/billing/user balance endpoints (exist in docs; not surfaced)
- ğŸŸ¡ Legacy completions / prefix/FIM flows (documented; not a first-class API in `llm_dart_deepseek`)

## Ollama (`llm_dart_ollama`)

Official docs:

- `https://github.com/ollama/ollama/blob/main/docs/api.md`

LLM Dart coverage:

- âœ… Chat
- âœ… Generate (completion)
- âœ… Embeddings
- âœ… Model listing (tags)
- â¬œ Model management endpoints (pull/push/create/copy/delete/ps/version)

## OpenRouter (config-only; OpenAI-compatible)

Official docs:

- `https://openrouter.ai/docs`

LLM Dart coverage:

- âœ… OpenAI-compatible Chat Completions via `llm_dart_openai_compatible`
- ğŸŸ¡ OpenRouter-specific behaviors (routing/model suffix conventions) via provider options
- â¬œ OpenRouter-native â€œmodels/creditsâ€ endpoints (not surfaced as first-class APIs)

## ElevenLabs (`llm_dart_elevenlabs`)

Official spec:

- `https://api.elevenlabs.io/openapi.json`

LLM Dart coverage:

- âœ… Text-to-speech (including streaming)
- âœ… Speech-to-text (transcription)
- âœ… Voices listing + basic voice settings defaults
- âœ… Speech-to-speech endpoints (provider-specific)
- âœ… Forced alignment endpoint (provider-specific)
- ğŸŸ¡ Provider-specific helpers (`getModels`, `getUserInfo`) exist but are not standardized
- â¬œ History / Studios / Workspace APIs (official API groups exist)
- â¬œ Realtime session transport (official products exist; provider currently throws `UnsupportedError`)
