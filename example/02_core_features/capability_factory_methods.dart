import 'dart:io';

import 'package:llm_dart_builder/llm_dart_builder.dart';
import 'package:llm_dart_core/llm_dart_core.dart';
import 'package:llm_dart_elevenlabs/llm_dart_elevenlabs.dart';
import 'package:llm_dart_openai/llm_dart_openai.dart';

/// üè≠ Capability Factory Methods - Type-Safe Provider Building
///
/// This example demonstrates the new capability factory methods that provide
/// type-safe access to specific provider capabilities at build time:
/// - buildAudio() - Returns AudioCapability directly
/// - buildImageGeneration() - Returns ImageGenerationCapability directly
/// - buildEmbedding() - Returns EmbeddingCapability directly
/// - buildFileManagement() - Returns FileManagementCapability directly
/// - buildModeration() - Returns ModerationCapability directly
/// - buildAssistant() - Returns AssistantCapability directly
/// - buildModelListing() - Returns ModelListingCapability directly
///
/// Benefits:
/// - Compile-time type safety
/// - No runtime type casting needed
/// - Clear error messages for unsupported capabilities
/// - Cleaner, more readable code
///
/// Before running, set your API keys:
/// export OPENAI_API_KEY="your-key"
/// export ELEVENLABS_API_KEY="your-key"
void main() async {
  print('üè≠ Capability Factory Methods - Type-Safe Provider Building\n');

  registerOpenAI();
  registerElevenLabs();

  // Demonstrate old vs new approach
  await demonstrateOldVsNewApproach();

  // Show type-safe capability building
  await demonstrateTypeSafeBuilding();

  // Show error handling for unsupported capabilities
  await demonstrateErrorHandling();

  // Show practical usage examples
  await demonstratePracticalUsage();

  print('\n‚úÖ Capability factory methods demo completed!');
  print('üìñ This approach provides compile-time type safety and cleaner code');
}

/// Demonstrate old vs new approach
Future<void> demonstrateOldVsNewApproach() async {
  print('üîÑ Old vs New Approach Comparison:\n');

  // final apiKey = Platform.environment['OPENAI_API_KEY'] ?? 'sk-TESTKEY';

  print('   üö® OLD APPROACH (runtime type casting):');
  print('   ```dart');
  print(
      '   final provider = await LLMBuilder().provider(openaiProviderId).apiKey(apiKey).build();');
  print('   if (provider is! AudioCapability) {');
  print('     throw Exception("Not supported");');
  print('   }');
  print(
      '   final audioProvider = provider as AudioCapability; // Runtime cast!');
  print('   final voices = await audioProvider.getVoices();');
  print('   ```');
  print('');

  print('   ‚úÖ NEW APPROACH (compile-time type safety):');
  print('   ```dart');
  print(
      '   final audioProvider = await LLMBuilder().provider(openaiProviderId).apiKey(apiKey).buildAudio();');
  print('   final voices = await audioProvider.getVoices(); // Direct usage!');
  print('   ```');
  print('');

  print('   üí° Benefits of new approach:');
  print('      ‚Ä¢ Compile-time type checking');
  print('      ‚Ä¢ No runtime type casting');
  print('      ‚Ä¢ Clear error messages');
  print('      ‚Ä¢ Better IDE support and autocomplete');
  print('      ‚Ä¢ Cleaner, more readable code');
  print('');
}

/// Demonstrate type-safe capability building
Future<void> demonstrateTypeSafeBuilding() async {
  print('üîí Type-Safe Capability Building:\n');

  final openaiKey = Platform.environment['OPENAI_API_KEY'];
  final elevenlabsKey = Platform.environment['ELEVENLABS_API_KEY'];

  if (openaiKey != null) {
    print('   ü§ñ OpenAI Provider Capabilities:');

    try {
      // Audio capability
      print('      üéµ Building audio capability...');
      final audioProvider = await LLMBuilder()
          .provider(openaiProviderId)
          .apiKey(openaiKey)
          .buildAudio();

      print('         ‚úÖ Audio provider built successfully');
      print('         Type: ${audioProvider.runtimeType}');

      // Test audio functionality
      final voices = await audioProvider.getVoices();
      print('         üé≠ Available voices: ${voices.length} voices');

      // Image generation capability
      print('      üñºÔ∏è  Building image generation capability...');
      final imageProvider = await LLMBuilder()
          .provider(openaiProviderId)
          .apiKey(openaiKey)
          .model('dall-e-3')
          .buildImageGeneration();

      print('         ‚úÖ Image generation provider built successfully');
      print('         Type: ${imageProvider.runtimeType}');

      // Test image generation functionality
      final formats = imageProvider.getSupportedFormats();
      print('         üé® Supported formats: ${formats.join(', ')}');

      // Embedding capability
      print('      üìä Building embedding capability...');
      final embeddingProvider = await LLMBuilder()
          .provider(openaiProviderId)
          .apiKey(openaiKey)
          .model('text-embedding-3-small')
          .buildEmbedding();

      print('         ‚úÖ Embedding provider built successfully');
      print('         Type: ${embeddingProvider.runtimeType}');

      // Test embedding functionality
      final embeddings = await embeddingProvider.embed(['Hello world']);
      print('         üî¢ Generated embeddings: ${embeddings.length} vectors');

      // Model listing capability
      print('      üìã Building model listing capability...');
      final modelProvider = await LLMBuilder()
          .provider(openaiProviderId)
          .apiKey(openaiKey)
          .buildModelListing();

      print('         ‚úÖ Model listing provider built successfully');
      print('         Type: ${modelProvider.runtimeType}');

      // Test model listing functionality
      final models = await modelProvider.models();
      print('         ü§ñ Available models: ${models.length} models');
    } catch (e) {
      print('      ‚ùå OpenAI capability building failed: $e');
    }
    print('');
  }

  if (elevenlabsKey != null) {
    print('   üéôÔ∏è ElevenLabs Provider Capabilities:');

    try {
      // Audio capability (ElevenLabs specializes in audio)
      print('      üéµ Building audio capability...');
      final audioProvider = await LLMBuilder()
          .provider(elevenLabsProviderId)
          .apiKey(elevenlabsKey)
          .providerOption('elevenlabs', 'voiceId', 'JBFqnCBsd6RMkjVDRZzb')
          .buildAudio();

      print('         ‚úÖ Audio provider built successfully');
      print('         Type: ${audioProvider.runtimeType}');

      // Test audio functionality
      final voices = await audioProvider.getVoices();
      print('         üé≠ Available voices: ${voices.length} voices');
      if (voices.isNotEmpty) {
        print(
            '         Sample voices: ${voices.take(3).map((v) => v.name).join(', ')}');
      }
    } catch (e) {
      print('      ‚ùå ElevenLabs capability building failed: $e');
    }
    print('');
  }

  if (openaiKey == null && elevenlabsKey == null) {
    print('   ‚ö†Ô∏è  No API keys available for demonstration');
    print('   Set OPENAI_API_KEY or ELEVENLABS_API_KEY to see live examples');
    print('');
  }
}

/// Demonstrate error handling for unsupported capabilities
Future<void> demonstrateErrorHandling() async {
  print('‚ö†Ô∏è  Error Handling for Unsupported Capabilities:\n');

  final elevenlabsKey = Platform.environment['ELEVENLABS_API_KEY'];

  if (elevenlabsKey != null) {
    print('   üß™ Testing unsupported capabilities with ElevenLabs:');

    // Try to build image generation with ElevenLabs (should fail)
    try {
      print('      üñºÔ∏è  Attempting to build image generation...');
      await LLMBuilder()
          .provider(elevenLabsProviderId)
          .apiKey(elevenlabsKey)
          .buildImageGeneration();

      print('         ‚ùå This should not succeed!');
    } catch (e) {
      print('         ‚úÖ Correctly caught error: ${e.runtimeType}');
      print('         üìù Error message: $e');
    }

    // Try to build embedding with ElevenLabs (should fail)
    try {
      print('      üìä Attempting to build embedding...');
      await LLMBuilder()
          .provider(elevenLabsProviderId)
          .apiKey(elevenlabsKey)
          .buildEmbedding();

      print('         ‚ùå This should not succeed!');
    } catch (e) {
      print('         ‚úÖ Correctly caught error: ${e.runtimeType}');
      print('         üìù Error message: $e');
    }

    print('');
  } else {
    print('   ‚ö†Ô∏è  Set ELEVENLABS_API_KEY to see error handling examples');
    print('');
  }
}

/// Demonstrate practical usage examples
Future<void> demonstratePracticalUsage() async {
  print('üöÄ Practical Usage Examples:\n');

  final openaiKey = Platform.environment['OPENAI_API_KEY'];

  if (openaiKey != null) {
    print('   üíº Real-world usage patterns:');

    // Example 1: Audio processing pipeline
    print('      üéµ Audio Processing Pipeline:');
    try {
      final audioProvider = await LLMBuilder()
          .provider(openaiProviderId)
          .apiKey(openaiKey)
          .buildAudio();

      // Direct usage without type casting
      final ttsResponse = await audioProvider.textToSpeech(TTSRequest(
        text: 'Hello from the new capability factory methods!',
        voice: 'alloy',
        format: 'mp3',
      ));

      print(
          '         ‚úÖ Generated speech: ${ttsResponse.audioData.length} bytes');
    } catch (e) {
      print('         ‚ùå Audio processing failed: $e');
    }

    // Example 2: Embedding similarity search
    print('      üìä Embedding Similarity Search:');
    try {
      final embeddingProvider = await LLMBuilder()
          .provider(openaiProviderId)
          .apiKey(openaiKey)
          .model('text-embedding-3-small')
          .buildEmbedding();

      // Direct usage without type casting
      final embeddings = await embeddingProvider.embed([
        'The new capability factory methods are great',
        'Type safety is important in software development',
        'Cats are cute animals',
      ]);

      print('         ‚úÖ Generated ${embeddings.length} embeddings');
      print('         üìè Vector dimensions: ${embeddings.first.length}');
    } catch (e) {
      print('         ‚ùå Embedding generation failed: $e');
    }

    // Example 3: Model discovery
    print('      üîç Model Discovery:');
    try {
      final modelProvider = await LLMBuilder()
          .provider(openaiProviderId)
          .apiKey(openaiKey)
          .buildModelListing();

      // Direct usage without type casting
      final models = await modelProvider.models();
      final gptModels = models.where((m) => m.id.contains('gpt')).toList();

      print('         ‚úÖ Found ${models.length} total models');
      print('         ü§ñ GPT models: ${gptModels.length}');
      if (gptModels.isNotEmpty) {
        print(
            '         Sample: ${gptModels.take(3).map((m) => m.id).join(', ')}');
      }
    } catch (e) {
      print('         ‚ùå Model listing failed: $e');
    }

    print('');
  } else {
    print('   ‚ö†Ô∏è  Set OPENAI_API_KEY to see practical usage examples');
    print('');
  }

  print('   üí° Key Benefits Demonstrated:');
  print('      ‚Ä¢ No type casting required');
  print('      ‚Ä¢ Compile-time type safety');
  print('      ‚Ä¢ Clear error messages for unsupported capabilities');
  print('      ‚Ä¢ Cleaner, more maintainable code');
  print('      ‚Ä¢ Better IDE support and autocomplete');
}
