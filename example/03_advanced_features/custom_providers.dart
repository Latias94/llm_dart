// ignore_for_file: avoid_print
import 'dart:io';
import 'dart:math';
import 'package:llm_dart/llm_dart.dart';

/// üîß Custom Providers - Build Your Own AI Providers
///
/// This example demonstrates how to create custom AI providers:
/// - Implementing the ChatCapability interface
/// - Adding custom functionality and behavior
/// - Integration with existing LLM Dart patterns
/// - Testing and validation strategies
///
/// Use cases for custom providers:
/// - Mock providers for testing
/// - Local model integration
/// - Custom API wrappers
/// - Specialized AI services
void main() async {
  print('üîß Custom Providers - Build Your Own AI Providers\n');

  // Demonstrate different custom provider scenarios
  await demonstrateMockProvider();
  await demonstrateLoggingProvider();
  await demonstrateCachingProvider();
  await demonstrateCustomAPIProvider();
  await demonstrateProviderChaining();

  print('\n‚úÖ Custom providers completed!');
}

/// Demonstrate a mock provider for testing
Future<void> demonstrateMockProvider() async {
  print('üé≠ Mock Provider for Testing:\n');

  try {
    // Create mock provider
    final mockProvider = MockChatProvider();

    // Test basic chat
    final response =
        await mockProvider.chat([ChatMessage.user('Hello, how are you?')]);

    print('   User: Hello, how are you?');
    print('   ü§ñ Mock AI: ${response.text}');

    // Test streaming
    print('\n   Streaming test:');
    print('   ü§ñ Mock AI: ');

    await for (final event
        in mockProvider.chatStream([ChatMessage.user('Count to 5')])) {
      switch (event) {
        case TextDeltaEvent(delta: final delta):
          stdout.write(delta);
          break;
        case CompletionEvent():
          print('\n');
          break;
        case ErrorEvent(error: final error):
          print('Error: $error');
          break;
        case ThinkingDeltaEvent():
        case ToolCallDeltaEvent():
          break;
      }
    }

    print('   üí° Mock Provider Benefits:');
    print('      ‚Ä¢ Predictable responses for testing');
    print('      ‚Ä¢ No API costs during development');
    print('      ‚Ä¢ Fast execution for unit tests');
    print('      ‚Ä¢ Controllable behavior and errors');
    print('   ‚úÖ Mock provider demonstration successful\n');
  } catch (e) {
    print('   ‚ùå Mock provider failed: $e\n');
  }
}

/// Demonstrate a logging provider wrapper
Future<void> demonstrateLoggingProvider() async {
  print('üìù Logging Provider Wrapper:\n');

  try {
    // Create base provider (mock for demo)
    final baseProvider = MockChatProvider();

    // Wrap with logging
    final loggingProvider = LoggingChatProvider(baseProvider);

    // Test with logging
    final response = await loggingProvider
        .chat([ChatMessage.user('What is artificial intelligence?')]);

    print('   User: What is artificial intelligence?');
    print('   ü§ñ AI: ${response.text}');

    print('\n   üí° Logging Provider Features:');
    print('      ‚Ä¢ Automatic request/response logging');
    print('      ‚Ä¢ Performance metrics collection');
    print('      ‚Ä¢ Error tracking and debugging');
    print('      ‚Ä¢ Transparent wrapper pattern');
    print('   ‚úÖ Logging provider demonstration successful\n');
  } catch (e) {
    print('   ‚ùå Logging provider failed: $e\n');
  }
}

/// Demonstrate a caching provider
Future<void> demonstrateCachingProvider() async {
  print('üíæ Caching Provider:\n');

  try {
    // Create base provider
    final baseProvider = MockChatProvider();

    // Wrap with caching
    final cachingProvider = CachingChatProvider(baseProvider);

    final question = 'What is the capital of France?';

    // First call - cache miss
    print('   First call (cache miss):');
    final stopwatch1 = Stopwatch()..start();
    final response1 = await cachingProvider.chat([ChatMessage.user(question)]);
    stopwatch1.stop();
    print('   ü§ñ AI: ${response1.text}');
    print('   ‚è±Ô∏è  Time: ${stopwatch1.elapsedMilliseconds}ms');

    // Second call - cache hit
    print('\n   Second call (cache hit):');
    final stopwatch2 = Stopwatch()..start();
    final response2 = await cachingProvider.chat([ChatMessage.user(question)]);
    stopwatch2.stop();
    print('   ü§ñ AI: ${response2.text}');
    print('   ‚è±Ô∏è  Time: ${stopwatch2.elapsedMilliseconds}ms');

    print('\n   üí° Caching Provider Benefits:');
    print('      ‚Ä¢ Faster responses for repeated queries');
    print('      ‚Ä¢ Reduced API costs');
    print('      ‚Ä¢ Better user experience');
    print('      ‚Ä¢ Configurable cache policies');
    print('   ‚úÖ Caching provider demonstration successful\n');
  } catch (e) {
    print('   ‚ùå Caching provider failed: $e\n');
  }
}

/// Demonstrate custom API provider
Future<void> demonstrateCustomAPIProvider() async {
  print('üåê Custom API Provider:\n');

  try {
    // Create custom API provider
    final customProvider = CustomAPIProvider(
      baseUrl: 'https://api.example.com',
      apiKey: 'custom-api-key',
      model: 'custom-model-v1',
    );

    // Test custom provider
    final response = await customProvider
        .chat([ChatMessage.user('Hello from custom provider!')]);

    print('   User: Hello from custom provider!');
    print('   ü§ñ Custom AI: ${response.text}');

    print('\n   üí° Custom API Provider Features:');
    print('      ‚Ä¢ Integration with proprietary APIs');
    print('      ‚Ä¢ Custom authentication methods');
    print('      ‚Ä¢ Specialized model configurations');
    print('      ‚Ä¢ Domain-specific optimizations');
    print('   ‚úÖ Custom API provider demonstration successful\n');
  } catch (e) {
    print('   ‚ùå Custom API provider failed: $e\n');
  }
}

/// Demonstrate provider chaining
Future<void> demonstrateProviderChaining() async {
  print('üîó Provider Chaining:\n');

  try {
    // Create base provider
    final baseProvider = MockChatProvider();

    // Chain multiple wrappers
    final chainedProvider =
        LoggingChatProvider(CachingChatProvider(baseProvider));

    // Test chained provider
    final response = await chainedProvider
        .chat([ChatMessage.user('Test chained providers')]);

    print('   User: Test chained providers');
    print('   ü§ñ Chained AI: ${response.text}');

    print('\n   üí° Provider Chaining Benefits:');
    print('      ‚Ä¢ Composable functionality');
    print('      ‚Ä¢ Separation of concerns');
    print('      ‚Ä¢ Reusable components');
    print('      ‚Ä¢ Flexible architecture');
    print('   ‚úÖ Provider chaining demonstration successful\n');
  } catch (e) {
    print('   ‚ùå Provider chaining failed: $e\n');
  }
}

/// Mock chat provider for testing
class MockChatProvider implements ChatCapability {
  final Random _random = Random();

  @override
  Future<ChatResponse> chat(
    List<ChatMessage> messages, {
    CancelToken? cancelToken,
  }) async {
    // Simulate API delay
    await Future.delayed(Duration(milliseconds: 100 + _random.nextInt(200)));

    final userMessage = messages.lastWhere(
      (m) => m.role == ChatRole.user,
      orElse: () => ChatMessage.user(''),
    );

    // Generate mock response based on user input
    final response = _generateMockResponse(userMessage.content.toString());

    return MockChatResponse(
      text: response,
      usage: MockUsage(
        promptTokens: 10 + _random.nextInt(20),
        completionTokens: 20 + _random.nextInt(30),
      ),
    );
  }

  @override
  Stream<ChatStreamEvent> chatStream(
    List<ChatMessage> messages, {
    List<Tool>? tools,
    CancelToken? cancelToken,
  }) async* {
    final userMessage = messages.lastWhere(
      (m) => m.role == ChatRole.user,
      orElse: () => ChatMessage.user(''),
    );

    final response = _generateMockResponse(userMessage.content.toString());
    final words = response.split(' ');

    // Stream words with delays
    for (final word in words) {
      await Future.delayed(Duration(milliseconds: 50 + _random.nextInt(100)));
      yield TextDeltaEvent('$word ');
    }

    yield CompletionEvent(MockChatResponse(
      text: response,
      usage: MockUsage(
        promptTokens: 10 + _random.nextInt(20),
        completionTokens: words.length,
      ),
    ));
  }

  @override
  Future<ChatResponse> chatWithTools(
    List<ChatMessage> messages,
    List<Tool>? tools, {
    CancelToken? cancelToken,
  }) async {
    return chat(messages, cancelToken: cancelToken); // Simple implementation
  }

  @override
  Future<List<ChatMessage>?> memoryContents() async => null;

  @override
  Future<String> summarizeHistory(List<ChatMessage> messages) async {
    return 'Mock summary of ${messages.length} messages';
  }

  String _generateMockResponse(String input) {
    final responses = [
      'This is a mock response to: $input',
      'Mock AI here! You said: $input',
      'Simulated response for testing purposes.',
      'Hello! This is a predictable mock response.',
      'Mock provider responding to your message.',
    ];
    return responses[_random.nextInt(responses.length)];
  }
}

/// Logging wrapper provider
class LoggingChatProvider implements ChatCapability {
  final ChatCapability _baseProvider;

  LoggingChatProvider(this._baseProvider);

  @override
  Future<ChatResponse> chat(
    List<ChatMessage> messages, {
    CancelToken? cancelToken,
  }) async {
    final stopwatch = Stopwatch()..start();

    print('   üìù [LOG] Starting chat request with ${messages.length} messages');

    try {
      final response = await _baseProvider.chat(messages, cancelToken: cancelToken);
      stopwatch.stop();

      print('   üìù [LOG] Chat completed in ${stopwatch.elapsedMilliseconds}ms');
      if (response.usage != null) {
        print('   üìù [LOG] Token usage: ${response.usage!.totalTokens}');
      }

      return response;
    } catch (e) {
      stopwatch.stop();
      print(
          '   üìù [LOG] Chat failed after ${stopwatch.elapsedMilliseconds}ms: $e');
      rethrow;
    }
  }

  @override
  Stream<ChatStreamEvent> chatStream(
    List<ChatMessage> messages, {
    List<Tool>? tools,
    CancelToken? cancelToken,
  }) async* {
    print('   üìù [LOG] Starting streaming chat request');

    await for (final event
        in _baseProvider.chatStream(messages, tools: tools, cancelToken: cancelToken)) {
      switch (event) {
        case TextDeltaEvent():
          print('   üìù [LOG] Text delta received');
          break;
        case CompletionEvent():
          print('   üìù [LOG] Stream completed');
          break;
        case ErrorEvent():
          print('   üìù [LOG] Stream error occurred');
          break;
        case ThinkingDeltaEvent():
        case ToolCallDeltaEvent():
          break;
      }
      yield event;
    }
  }

  @override
  Future<ChatResponse> chatWithTools(
    List<ChatMessage> messages,
    List<Tool>? tools, {
    CancelToken? cancelToken,
  }) async {
    print('   üìù [LOG] Chat with ${tools?.length ?? 0} tools');
    return _baseProvider.chatWithTools(messages, tools, cancelToken: cancelToken);
  }

  @override
  Future<List<ChatMessage>?> memoryContents() async {
    print('   üìù [LOG] Getting memory contents');
    return _baseProvider.memoryContents();
  }

  @override
  Future<String> summarizeHistory(List<ChatMessage> messages) async {
    print('   üìù [LOG] Summarizing ${messages.length} messages');
    return _baseProvider.summarizeHistory(messages);
  }
}

/// Caching wrapper provider
class CachingChatProvider implements ChatCapability {
  final ChatCapability _baseProvider;
  final Map<String, ChatResponse> _cache = {};

  CachingChatProvider(this._baseProvider);

  @override
  Future<ChatResponse> chat(
    List<ChatMessage> messages, {
    CancelToken? cancelToken,
  }) async {
    final cacheKey = _generateCacheKey(messages);

    if (_cache.containsKey(cacheKey)) {
      print('   üíæ [CACHE] Cache hit for request');
      return _cache[cacheKey]!;
    }

    print('   üíæ [CACHE] Cache miss, calling base provider');
    final response = await _baseProvider.chat(messages, cancelToken: cancelToken);
    _cache[cacheKey] = response;

    return response;
  }

  @override
  Stream<ChatStreamEvent> chatStream(
    List<ChatMessage> messages, {
    List<Tool>? tools,
    CancelToken? cancelToken,
  }) {
    // For simplicity, streaming bypasses cache
    return _baseProvider.chatStream(messages, tools: tools, cancelToken: cancelToken);
  }

  @override
  Future<ChatResponse> chatWithTools(
    List<ChatMessage> messages,
    List<Tool>? tools, {
    CancelToken? cancelToken,
  }) {
    // Tools bypass cache for safety
    return _baseProvider.chatWithTools(messages, tools, cancelToken: cancelToken);
  }

  @override
  Future<List<ChatMessage>?> memoryContents() async {
    return _baseProvider.memoryContents();
  }

  @override
  Future<String> summarizeHistory(List<ChatMessage> messages) async {
    return _baseProvider.summarizeHistory(messages);
  }

  String _generateCacheKey(List<ChatMessage> messages) {
    return messages.map((m) => '${m.role}:${m.content}').join('|');
  }
}

/// Custom API provider example
class CustomAPIProvider implements ChatCapability {
  final String baseUrl;
  final String apiKey;
  final String model;

  CustomAPIProvider({
    required this.baseUrl,
    required this.apiKey,
    required this.model,
  });

  @override
  Future<ChatResponse> chat(
    List<ChatMessage> messages, {
    CancelToken? cancelToken,
  }) async {
    // Simulate custom API call
    await Future.delayed(Duration(milliseconds: 300));

    return MockChatResponse(
      text: 'Response from custom API at $baseUrl using model $model',
      usage: MockUsage(promptTokens: 15, completionTokens: 25),
    );
  }

  @override
  Stream<ChatStreamEvent> chatStream(
    List<ChatMessage> messages, {
    List<Tool>? tools,
    CancelToken? cancelToken,
  }) async* {
    final response = await chat(messages, cancelToken: cancelToken);
    yield TextDeltaEvent(response.text ?? '');
    yield CompletionEvent(response);
  }

  @override
  Future<ChatResponse> chatWithTools(
    List<ChatMessage> messages,
    List<Tool>? tools, {
    CancelToken? cancelToken,
  }) {
    return chat(messages, cancelToken: cancelToken);
  }

  @override
  Future<List<ChatMessage>?> memoryContents() async => null;

  @override
  Future<String> summarizeHistory(List<ChatMessage> messages) async {
    return 'Custom API summary of ${messages.length} messages';
  }
}

/// Mock implementations for testing
class MockChatResponse implements ChatResponse {
  @override
  final String? text;

  @override
  final UsageInfo? usage;

  @override
  final String? thinking;

  @override
  final List<ToolCall>? toolCalls;

  MockChatResponse({
    required this.text,
    this.usage,
    this.thinking,
    this.toolCalls,
  });
}

class MockUsage extends UsageInfo {
  MockUsage({
    required int promptTokens,
    required int completionTokens,
  }) : super(
          promptTokens: promptTokens,
          completionTokens: completionTokens,
          totalTokens: promptTokens + completionTokens,
        );
}

/// üéØ Key Custom Provider Concepts Summary:
///
/// Provider Interface:
/// - ChatCapability: Core interface to implement
/// - chat(): Single request/response
/// - chatStream(): Streaming responses
/// - chatWithTools(): Tool-enabled chat
///
/// Implementation Patterns:
/// - Mock providers: Testing and development
/// - Wrapper providers: Add functionality to existing providers
/// - Custom API providers: Integrate proprietary services
/// - Chained providers: Compose multiple behaviors
///
/// Common Use Cases:
/// - Testing and mocking
/// - Logging and monitoring
/// - Caching and optimization
/// - Custom API integration
/// - Rate limiting and throttling
///
/// Best Practices:
/// 1. Implement all required interface methods
/// 2. Handle errors gracefully
/// 3. Maintain consistent behavior
/// 4. Document custom functionality
/// 5. Test thoroughly with edge cases
///
/// Advanced Patterns:
/// - Provider factories for configuration
/// - Async initialization and cleanup
/// - Health checks and monitoring
/// - Fallback and retry logic
///
/// Next Steps:
/// - performance_optimization.dart: Production optimization
/// - ../02_core_features/error_handling.dart: Robust error handling
/// - ../06_integration/: Production integration patterns
