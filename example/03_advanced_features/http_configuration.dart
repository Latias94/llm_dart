import 'dart:io';

import 'package:llm_dart_ai/llm_dart_ai.dart';
import 'package:llm_dart_builder/llm_dart_builder.dart';
import 'package:llm_dart_core/llm_dart_core.dart';
import 'package:llm_dart_openai/llm_dart_openai.dart';
import 'package:llm_dart_provider_utils/llm_dart_provider_utils.dart';
import 'package:logging/logging.dart';

/// HTTP Configuration Example
///
/// This example demonstrates how to configure HTTP settings for LLM providers,
/// including proxy configuration, custom headers, SSL settings, and logging.
///
/// Note: Advanced HTTP features (proxy, SSL bypass, custom certificates) are only
/// available on IO platforms (Desktop/Mobile/Server). On Web platforms, these
/// features are managed by the browser.
///
/// Before running, set your OpenAI API key:
/// export OPENAI_API_KEY="your-openai-key"
Future<void> main() async {
  // Configure logging to see HTTP request/response logs
  Logger.root.level = Level.ALL;
  Logger.root.onRecord.listen((record) {
    print('${record.level.name}: ${record.time}: ${record.message}');
  });

  print('üåê HTTP Configuration Demo\n');

  registerOpenAI();

  // Get OpenAI API key from environment
  final openaiApiKey = Platform.environment['OPENAI_API_KEY'];

  if (openaiApiKey == null) {
    print('‚ùå Please set your OpenAI API key:');
    print('   export OPENAI_API_KEY="your-openai-key"');
    return;
  }

  print('üìã Using OpenAI provider for all demonstrations\n');

  // Run all demonstrations with OpenAI
  await demonstrateBasicHttpConfig(openaiApiKey);
  await demonstrateProxyConfiguration(openaiApiKey);
  await demonstrateSSLConfiguration(openaiApiKey);
  await demonstrateCustomHeaders(openaiApiKey);
  await demonstrateTimeoutConfiguration(openaiApiKey);
  await demonstrateLoggingConfiguration(openaiApiKey);
  await demonstrateComprehensiveConfig(openaiApiKey);

  // await demonstrateConfigValidation();

  print('‚úÖ HTTP configuration demonstration completed!');
}

/// Demonstrate basic HTTP configuration
Future<void> demonstrateBasicHttpConfig(String apiKey) async {
  print('üîß Basic HTTP Configuration:\n');

  try {
    // Create provider with basic HTTP settings
    final provider = await LLMBuilder()
        .provider(openaiProviderId)
        .apiKey(apiKey)
        .model('gpt-4o-mini')
        .timeout(Duration(seconds: 30))
        .build();

    final result = await generateText(
      model: provider,
      messages: [
        ChatMessage.user(
            'Hello! This is a test with basic HTTP configuration.'),
      ],
    );

    print('   ‚úÖ Basic HTTP configuration successful');
    print('   üìù Response: ${result.text}\n');
  } catch (e) {
    print('   ‚ùå Basic HTTP configuration failed: $e\n');
  }
}

/// Demonstrate proxy configuration
Future<void> demonstrateProxyConfiguration(String apiKey) async {
  print('üîÑ Proxy Configuration:\n');
  print('   ‚ÑπÔ∏è  Note: Proxy configuration is only supported on IO platforms');
  print('   üìù On Web platforms, proxy settings are managed by the browser\n');

  try {
    // Note: This example shows the API usage. In practice, you would
    // need a real proxy server for this to work.
    await LLMBuilder()
        .provider(openaiProviderId)
        .apiKey(apiKey)
        .model('gpt-4o-mini')
        .http((http) => http.proxy('http://proxy.company.com:8080'))
        .build();

    print('   ‚úÖ Proxy configuration set successfully');
    print('   üìù Note: Proxy will be used for all HTTP requests\n');
  } catch (e) {
    print(
        '   ‚ö†Ô∏è  Proxy configuration example (may fail without real proxy): $e\n');
  }
}

/// Demonstrate custom headers configuration
Future<void> demonstrateCustomHeaders(String openaiApiKey) async {
  print('üìã Custom Headers Configuration (OpenAI):\n');

  try {
    final provider = await LLMBuilder()
        .provider(openaiProviderId)
        .apiKey(openaiApiKey)
        .model('gpt-4o-mini')
        .http((http) => http.headers({
              'X-Request-ID': 'demo-request-123',
              'X-Client-Version': '1.0.0',
              'User-Agent': 'LLMDart-Demo/1.0',
            }).header('X-Additional-Header', 'additional-value'))
        .build();

    final result = await generateText(
      model: provider,
      messages: [
        ChatMessage.user('Hello! This request includes custom headers.')
      ],
    );

    print('   ‚úÖ Custom headers configuration successful');
    print('   üìù Response: ${result.text}\n');
  } catch (e) {
    print('   ‚ùå Custom headers configuration failed: $e\n');
  }
}

/// Demonstrate SSL configuration
Future<void> demonstrateSSLConfiguration(String openaiApiKey) async {
  print('üîí SSL Configuration:\n');
  print('   ‚ÑπÔ∏è  Note: SSL configuration is only supported on IO platforms');
  print('   üìù On Web platforms, SSL/TLS is managed by the browser\n');

  try {
    // Example with SSL verification bypass (for development only)
    await LLMBuilder()
        .provider(openaiProviderId)
        .apiKey(openaiApiKey)
        .model('gpt-4o-mini')
        .http((http) =>
            http.bypassSSLVerification(true)) // ‚ö†Ô∏è Only for development!
        .build();

    print('   ‚ö†Ô∏è  SSL verification bypass enabled (development only)');
    print('   üìù Note: This should only be used for local development\n');
  } catch (e) {
    print('   ‚ö†Ô∏è  SSL verification bypass example: $e\n');
  }

  try {
    // Example with custom SSL certificate
    await LLMBuilder()
        .provider(openaiProviderId)
        .apiKey(openaiApiKey)
        .model('gpt-4o-mini')
        .http((http) => http.sslCertificate('/path/to/custom/certificate.pem'))
        .build();

    print('   ‚úÖ Custom SSL certificate configuration set');
    print('   üìù Note: Certificate path configured for secure connections\n');
  } catch (e) {
    print('   ‚ö†Ô∏è  Custom SSL certificate example: $e\n');
  }
}

/// Demonstrate timeout configuration with priority hierarchy
Future<void> demonstrateTimeoutConfiguration(String openaiApiKey) async {
  print('‚è±Ô∏è  Timeout Configuration (OpenAI - Priority Hierarchy):\n');

  try {
    // Example 1: Global timeout only
    print('   üìù Example 1: Global timeout only');
    final provider1 = await LLMBuilder()
        .provider(openaiProviderId)
        .apiKey(openaiApiKey)
        .model('gpt-4o-mini')
        .timeout(Duration(minutes: 1)) // Global timeout for all operations
        .build();

    final result1 = await generateText(
      model: provider1,
      messages: [ChatMessage.user('Hello! This uses global timeout.')],
    );
    print('   ‚úÖ Global timeout: connection=1m, receive=1m, send=1m');
    print('   üìù Response: ${result1.text}\n');

    // Example 2: Mixed configuration (global + HTTP overrides)
    print('   üìù Example 2: Mixed configuration (global + HTTP overrides)');
    final provider2 = await LLMBuilder()
        .provider(openaiProviderId)
        .apiKey(openaiApiKey)
        .model('gpt-4o-mini')
        .timeout(Duration(minutes: 2)) // Global default: 2 minutes
        .http((http) => http
            .connectionTimeout(
                Duration(seconds: 15)) // Override connection: 15s
            .receiveTimeout(Duration(minutes: 3))) // Override receive: 3m
        // sendTimeout will use global timeout (2 minutes)
        .build();

    final result2 = await generateText(
      model: provider2,
      messages: [
        ChatMessage.user('Hello! This uses mixed timeout configuration.'),
      ],
    );
    print('   ‚úÖ Mixed timeouts: connection=15s, receive=3m, send=2m');
    print('   üìù Priority: HTTP-specific > Global > Provider defaults');
    print('   üìù Response: ${result2.text}\n');
  } catch (e) {
    print('   ‚ùå Timeout configuration failed: $e\n');
  }
}

/// Demonstrate logging configuration
Future<void> demonstrateLoggingConfiguration(String openaiApiKey) async {
  print('üìä HTTP Logging Configuration (OpenAI):\n');

  try {
    final provider = await LLMBuilder()
        .provider(openaiProviderId)
        .apiKey(openaiApiKey)
        .model('gpt-4o-mini')
        .http((http) => http.enableLogging(true))
        .build();

    print('   ‚úÖ HTTP logging enabled');
    print('   üìù All HTTP requests and responses will be logged');
    print('   üìù Making a test request...\n');

    final result = await generateText(
      model: provider,
      messages: [ChatMessage.user('Hello! This request will be logged.')],
    );

    print('   ‚úÖ Request completed with logging');
    print('   üìù Response: ${result.text}\n');
  } catch (e) {
    print('   ‚ùå Logging configuration failed: $e\n');
  }
}

/// Demonstrate comprehensive HTTP configuration
Future<void> demonstrateComprehensiveConfig(String openaiApiKey) async {
  print('üéØ Comprehensive HTTP Configuration (OpenAI):\n');

  try {
    final provider = await LLMBuilder()
        .provider(openaiProviderId)
        .apiKey(openaiApiKey)
        .model('gpt-4o-mini')
        // HTTP configuration using the new layered approach
        .http((http) => http
            .headers({
              'X-Request-ID': 'comprehensive-demo-456',
              'X-Client-Name': 'LLMDart-Comprehensive-Demo',
            })
            .connectionTimeout(Duration(seconds: 20))
            .receiveTimeout(Duration(minutes: 3))
            .enableLogging(true))
        // Provider-specific configuration
        .temperature(0.7)
        .maxTokens(1000)
        .build();

    final result = await generateText(
      model: provider,
      messages: [
        ChatMessage.user(
          'Hello! This request uses comprehensive HTTP configuration.',
        ),
      ],
    );

    print('   ‚úÖ Comprehensive configuration successful');
    print('   üìù All HTTP settings applied successfully');
    print('   üìù Response: ${result.text}\n');
  } catch (e) {
    print('   ‚ùå Comprehensive configuration failed: $e\n');
  }
}

/// Demonstrate configuration validation
Future<void> demonstrateConfigValidation() async {
  print('‚úÖ Configuration Validation:\n');

  try {
    // This would typically be called internally, but shown here for demonstration
    final config = LLMConfig(
      baseUrl: 'https://api.openai.com/v1/',
      model: 'gpt-4o-mini',
      apiKey: 'test-key',
      timeout: Duration(seconds: 60),
    ).withTransportOptions({
      'httpProxy': 'invalid-proxy-url', // This will trigger a warning
      'bypassSSLVerification': true, // This will trigger a security warning
      'connectionTimeout':
          Duration(seconds: 30), // Different from global timeout
    });

    HttpConfigUtils.validateHttpConfig(config);
    print('   ‚úÖ Configuration validation completed');
    print('   üìù Check logs for any warnings about configuration issues\n');
  } catch (e) {
    print('   ‚ùå Configuration validation failed: $e\n');
  }
}
